{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebe3765",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchdiffeq\n",
    "import torchsde\n",
    "from torchdyn.core import NeuralODE\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "from geomloss import SamplesLoss\n",
    "from pykeops.torch import LazyTensor\n",
    "\n",
    "from torchcfm.conditional_flow_matching import *\n",
    "from torchcfm.models.unet import UNetModel\n",
    "\n",
    "os.environ[\"WANDB_API_KEY\"] = \"ab7ab794a522f2467a9c6cb33f3a0220488f3ee7\" # Change to your W&B profile if you need it\n",
    "os.environ[\"WANDB_MODE\"] = \"online\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a911a419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"CFM_EEG2ECoG\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"architecture\": \"SB_CFM\",\n",
    "    \"dataset\": \"EEG2ECoG\",\n",
    "    \"epochs\": 250,\n",
    "    \"Lambda\":25,\n",
    "    \"DiscFilters\": 48,\n",
    "    \"GenFilters\": 96\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e1a7d",
   "metadata": {},
   "source": [
    "# Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cebec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "class TopoMapDataset(Dataset):\n",
    "    def __init__(self, data_directory, ids, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = [] \n",
    "\n",
    "        for subject_id in ids:\n",
    "            eeg_file_path = os.path.join(data_directory, f\"response_gen_topo_eeg_{subject_id}.png\")\n",
    "            ecog_file_path = os.path.join(data_directory, f\"response_gen_topo_ecog_{subject_id}.png\")\n",
    "\n",
    "            if os.path.exists(eeg_file_path) and os.path.exists(ecog_file_path):\n",
    "                eeg_image = Image.open(eeg_file_path)\n",
    "                ecog_image = Image.open(ecog_file_path)\n",
    "\n",
    "                if self.transform:\n",
    "                    eeg_image = self.transform(eeg_image)\n",
    "                    ecog_image = self.transform(ecog_image)\n",
    "\n",
    "                self.data.append((subject_id, eeg_image, ecog_image))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def convert_to_four_channels(self, image):\n",
    "        # Convert single-channel image to four channels\n",
    "        if image.mode == 'L':\n",
    "            image = image.convert('RGBA')\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject_id, eeg_image, ecog_image = self.data[idx]\n",
    "\n",
    "        # Convert to four channels if needed\n",
    "        eeg_image = self.convert_to_four_channels(eeg_image)\n",
    "        ecog_image = self.convert_to_four_channels(ecog_image)\n",
    "\n",
    "        data_dict = {\n",
    "            \"subject_id\": subject_id,\n",
    "            \"eeg_image\": eeg_image,\n",
    "            \"ecog_image\": ecog_image\n",
    "        }\n",
    "\n",
    "        return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed42f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names_eeg = [f for f in os.listdir(data_directory) if f.startswith(\"response_gen_topo_eeg\")]\n",
    "file_names_ecog = [f for f in os.listdir(data_directory) if f.startswith(\"response_gen_topo_ecog\")]\n",
    "file_ids_eeg = list(set([file.split('_')[0] for file in file_names_eeg]))\n",
    "file_ids_ecog = list(set([file.split('_')[0] for file in file_names_ecog]))\n",
    "\n",
    "file_ids =set(file_ids_eeg) & set(file_ids_ecog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f59bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ca656",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = [f.split(\"_\")[-1].split(\".\")[0] for f in file_names_eeg]\n",
    "dataset = TopoMapDataset(data_directory=data_directory, ids=unique_ids, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "batch_size = 10\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8107ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "index_to_display = 10\n",
    "data_item = train_dataset[index_to_display]\n",
    "\n",
    "eeg_image = data_item['eeg_image']\n",
    "ecog_image = data_item['ecog_image']\n",
    "\n",
    "to_pil = ToPILImage()\n",
    "eeg_pil_image = to_pil(eeg_image)\n",
    "ecog_pil_image = to_pil(ecog_image)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(eeg_pil_image)\n",
    "axes[0].set_title('EEG Image')\n",
    "\n",
    "axes[1].imshow(ecog_pil_image)\n",
    "axes[1].set_title('ECoG Image')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18986dde",
   "metadata": {},
   "source": [
    "# Exact Optimal Transport Conditional Flow Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6622fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.1\n",
    "n_epochs = 250\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = UNetModel(\n",
    "    dim=(4, 128, 128), \n",
    "    num_channels=32, \n",
    "    num_res_blocks=1, \n",
    "    num_classes=None, \n",
    "    class_cond=False\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "FM = ExactOptimalTransportConditionalFlowMatcher(sigma=sigma) \n",
    "node = NeuralODE(model, solver=\"dopri5\", sensitivity=\"adjoint\", atol=1e-4, rtol=1e-4).to(device)\n",
    "\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02ae9a2",
   "metadata": {},
   "source": [
    "# Physiologically Inspired Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e1f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian_loss(pred_image, true_image):\n",
    "    laplacian_filter = torch.tensor([[0, 1, 0], [1, -4, 1], [0, 1, 0]]).float().unsqueeze(0).unsqueeze(0).to(pred_image.device)\n",
    "    laplacian_filter = laplacian_filter.repeat(pred_image.shape[1], 1, 1, 1)  # Повторяем для каждого канала\n",
    "    pred_laplace = F.conv2d(pred_image, laplacian_filter, padding=1, groups=pred_image.shape[1])\n",
    "    true_laplace = F.conv2d(true_image, laplacian_filter, padding=1, groups=true_image.shape[1])\n",
    "    \n",
    "    return F.mse_loss(pred_laplace, true_laplace)\n",
    "\n",
    "def wasserstein_loss(eeg_image, ecog_image):\n",
    "    samples_loss = SamplesLoss(loss=\"sinkhorn\", p=2, blur=0.05)\n",
    "    B, C, H, W = eeg_image.size()  # Batch, Channels, Height, Width\n",
    "    eeg_image_flat = eeg_image.view(B, -1, C)  \n",
    "    ecog_image_flat = ecog_image.view(B, -1, C)\n",
    "    \n",
    "    return samples_loss(eeg_image_flat, ecog_image_flat)\n",
    "\n",
    "def hybrid_loss(model_output, true_image, eeg_image, alpha=0.5, beta=0.4, gamma=0.1):\n",
    "    # MSE Loss (Mean Squared Error)\n",
    "    mse_loss = F.mse_loss(model_output, true_image)\n",
    "    # Wasserstein Loss\n",
    "    wass_loss = wasserstein_loss(model_output, true_image)\n",
    "    # Laplacian Loss\n",
    "    laplace_loss = laplacian_loss(model_output, true_image)\n",
    "    total_loss = alpha * wass_loss + beta * mse_loss + gamma * laplace_loss\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1098dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pil = ToPILImage()\n",
    "index_to_display = 100\n",
    "data_item = test_dataset[index_to_display]\n",
    "\n",
    "eeg_image_path = data_item[\"eeg_image\"]\n",
    "eeg_image = to_pil(eeg_image_path)\n",
    "eeg_image_tensor = transform(eeg_image).unsqueeze(0).to(device)\n",
    "\n",
    "ecog_image_path = data_item[\"ecog_image\"]\n",
    "ecog_image = to_pil(ecog_image_path)\n",
    "ecog_image_tensor = transform(ecog_image).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af64b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(n_epochs)):\n",
    "    for i, data in enumerate(train_data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        eeg_image = data[\"eeg_image\"].to(device)\n",
    "        ecog_image = data[\"ecog_image\"].to(device)\n",
    "        x0 = torch.randn_like(eeg_image)\n",
    "        \n",
    "        t, xt, ut = FM.sample_location_and_conditional_flow(x0, ecog_image)\n",
    "        vt = model(t, xt)\n",
    "        \n",
    "        # Вычисление потерь\n",
    "        loss = hybrid_loss(vt, ecog_image, eeg_image, alpha=0.5, beta=0.4, gamma=0.1)\n",
    "        loss = loss.mean() \n",
    "        wandb.log({\"EOT_CFM_loss\": loss})\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"epoch: {epoch}, steps: {i}, loss: {loss.item():.4}\", end=\"\\r\")\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            end = time.time()\n",
    "            start = end\n",
    "            node = NeuralODE(model, solver=\"dopri5\", sensitivity=\"adjoint\", atol=1e-4, rtol=1e-4).to(device)\n",
    "            with torch.no_grad():\n",
    "                traj = torchdiffeq.odeint(\n",
    "                    lambda t, x: model.forward(t, x), \n",
    "                    eeg_image_tensor,\n",
    "                    torch.linspace(0, 1, 2, device=device),\n",
    "                    atol=1e-4,\n",
    "                    rtol=1e-4,\n",
    "                    method=\"dopri5\",\n",
    "                )\n",
    "                eeg_image_display = ToPILImage()(eeg_image_tensor.squeeze(0).cpu())\n",
    "                ecog_image_display = ToPILImage()(ecog_image_tensor.squeeze(0).cpu())\n",
    "\n",
    "                generated_ecog = traj[-1, :1].view([-1, 4, 128, 128]).clip(-1, 1)\n",
    "                grid = make_grid(generated_ecog, value_range=(-1, 1), padding=0, nrow=1)\n",
    "                generated_ecog_display = ToPILImage()(grid)\n",
    "\n",
    "                fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                # Плотинг ЭЭГ\n",
    "                axs[0].imshow(eeg_image_display)\n",
    "                axs[0].set_title(\"Input EEG\")\n",
    "                axs[0].axis('off')\n",
    "                # Плотинг ЭКоГ\n",
    "                axs[1].imshow(ecog_image_display)\n",
    "                axs[1].set_title(\"Target ECoG\")\n",
    "                axs[1].axis('off')\n",
    "                # Плотинг сгенерированного ЭКоГ\n",
    "                axs[2].imshow(generated_ecog_display)\n",
    "                axs[2].set_title(\"Generated ECoG from EEG by EOTCFM\")\n",
    "                axs[2].axis('off')\n",
    "\n",
    "    torch.save(model_SB.state_dict(), '/beegfs/home/ruslan.kalimullin/GenAI_course/Project/Weights/CFM_EOT_epoch=%d.pth' % (epoch))\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1278afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_TORCH_DIFFEQ = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_directory = \"/beegfs/home/ruslan.kalimullin/MScThesis/topo-maps\"\n",
    "\n",
    "to_pil = ToPILImage()\n",
    "index_to_display = 100\n",
    "data_item = test_dataset[index_to_display]\n",
    "\n",
    "eeg_image_path = data_item[\"eeg_image\"]\n",
    "eeg_image = to_pil(eeg_image_path)\n",
    "eeg_image_tensor = transform(eeg_image).unsqueeze(0).to(device)\n",
    "\n",
    "ecog_image_path = data_item[\"ecog_image\"]\n",
    "ecog_image = to_pil(ecog_image_path)\n",
    "ecog_image_tensor = transform(ecog_image).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "# Модель forward принимает тензор времени t, тензор входа (например, eeg_image) и условие (ecog_image)\n",
    "with torch.no_grad():\n",
    "    if USE_TORCH_DIFFEQ:\n",
    "        # Пример траектории для преобразования ЭЭГ в ЭКоГ\n",
    "        traj = torchdiffeq.odeint(\n",
    "            lambda t, x: model.forward(t, x),  # Без передачи y\n",
    "            eeg_image_tensor,\n",
    "            torch.linspace(0, 1, 2, device=device),\n",
    "            atol=1e-4,\n",
    "            rtol=1e-4,\n",
    "            method=\"dopri5\",\n",
    "        )\n",
    "    else:\n",
    "        # Альтернатива без использования torchdiffeq\n",
    "        traj = node.trajectory(\n",
    "            eeg_image_tensor,  # Входные данные ЭЭГ\n",
    "            t_span=torch.linspace(0, 1, 2, device=device),  # Временной интервал\n",
    "        )\n",
    "\n",
    "eeg_image_display = ToPILImage()(eeg_image_tensor.squeeze(0).cpu())\n",
    "ecog_image_display = ToPILImage()(ecog_image_tensor.squeeze(0).cpu())\n",
    "\n",
    "generated_ecog = traj[-1, :1].view([-1, 4, 128, 128]).clip(-1, 1)\n",
    "grid = make_grid(generated_ecog, value_range=(-1, 1), padding=0, nrow=1)\n",
    "generated_ecog_display = ToPILImage()(grid)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].imshow(eeg_image_display)\n",
    "axs[0].set_title(\"Input EEG\")\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(ecog_image_display)\n",
    "axs[1].set_title(\"Target ECoG\")\n",
    "axs[1].axis('off')\n",
    "axs[2].imshow(generated_ecog_display)\n",
    "axs[2].set_title(\"Generated ECoG from EEG\")\n",
    "axs[2].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d7f232",
   "metadata": {},
   "source": [
    "# Shrodinger Bridge Conditional Flow Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe76f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.1\n",
    "n_epochs = 250\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_SB = UNetModel(\n",
    "    dim=(4, 128, 128), \n",
    "    num_channels=32, \n",
    "    num_res_blocks=1, \n",
    "    num_classes=None, \n",
    "    class_cond=False\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model_SB.parameters())\n",
    "FM = SchrodingerBridgeConditionalFlowMatcher(sigma=sigma) \n",
    "node = NeuralODE(model_SB, solver=\"dopri5\", sensitivity=\"adjoint\", atol=1e-4, rtol=1e-4).to(device)\n",
    "\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596c2ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pil = ToPILImage()\n",
    "index_to_display = 100\n",
    "data_item = test_dataset[index_to_display]\n",
    "\n",
    "eeg_image_path = data_item[\"eeg_image\"]\n",
    "eeg_image = to_pil(eeg_image_path)\n",
    "eeg_image_tensor = transform(eeg_image).unsqueeze(0).to(device)\n",
    "\n",
    "ecog_image_path = data_item[\"ecog_image\"]\n",
    "ecog_image = to_pil(ecog_image_path)\n",
    "ecog_image_tensor = transform(ecog_image).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa22ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(n_epochs)):\n",
    "    for i, data in enumerate(train_data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        eeg_image = data[\"eeg_image\"].to(device)\n",
    "        ecog_image = data[\"ecog_image\"].to(device)\n",
    "        \n",
    "        # Генерация случайного шума\n",
    "        x0 = torch.randn_like(eeg_image)\n",
    "        \n",
    "        # Выборка и предсказание\n",
    "        t, xt, ut = FM.sample_location_and_conditional_flow(x0, ecog_image)\n",
    "        vt = model_SB(t, xt)\n",
    "        \n",
    "        # Вычисление потерь\n",
    "        loss = hybrid_loss(vt, ecog_image, eeg_image, alpha=0.5, beta=0.4, gamma=0.1)\n",
    "        loss = loss.mean() \n",
    "        wandb.log({\"SB_CFM_loss\": loss})\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"epoch: {epoch}, steps: {i}, loss: {loss.item():.4}\", end=\"\\r\")\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            end = time.time()\n",
    "            start = end\n",
    "            node = NeuralODE(model_SB, solver=\"dopri5\", sensitivity=\"adjoint\", atol=1e-4, rtol=1e-4).to(device)\n",
    "            with torch.no_grad():\n",
    "                traj = torchdiffeq.odeint(\n",
    "                    lambda t, x: model_SB.forward(t, x), \n",
    "                    eeg_image_tensor,\n",
    "                    torch.linspace(0, 1, 2, device=device),\n",
    "                    atol=1e-4,\n",
    "                    rtol=1e-4,\n",
    "                    method=\"dopri5\",\n",
    "                )\n",
    "                eeg_image_display = ToPILImage()(eeg_image_tensor.squeeze(0).cpu())\n",
    "                ecog_image_display = ToPILImage()(ecog_image_tensor.squeeze(0).cpu())\n",
    "\n",
    "                generated_ecog = traj[-1, :1].view([-1, 4, 128, 128]).clip(-1, 1)\n",
    "                grid = make_grid(generated_ecog, value_range=(-1, 1), padding=0, nrow=1)\n",
    "                generated_ecog_display = ToPILImage()(grid)\n",
    "\n",
    "                fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                # Плотинг ЭЭГ\n",
    "                axs[0].imshow(eeg_image_display)\n",
    "                axs[0].set_title(\"Input EEG\")\n",
    "                axs[0].axis('off')\n",
    "                # Плотинг ЭКоГ\n",
    "                axs[1].imshow(ecog_image_display)\n",
    "                axs[1].set_title(\"Target ECoG\")\n",
    "                axs[1].axis('off')\n",
    "                # Плотинг сгенерированного ЭКоГ\n",
    "                axs[2].imshow(generated_ecog_display)\n",
    "                axs[2].set_title(\"Generated ECoG from EEG by EOTCFM\")\n",
    "                axs[2].axis('off')\n",
    "\n",
    "    torch.save(model_SB.state_dict(), '/beegfs/home/ruslan.kalimullin/GenAI_course/Project/Weights/CFM_SB_epoch=%d.pth' % (epoch))\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64f5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_TORCH_DIFFEQ = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_directory = \"/beegfs/home/ruslan.kalimullin/MScThesis/topo-maps\"\n",
    "\n",
    "to_pil = ToPILImage()\n",
    "index_to_display = 100\n",
    "data_item = test_dataset[index_to_display]\n",
    "\n",
    "eeg_image_path = data_item[\"eeg_image\"]\n",
    "eeg_image = to_pil(eeg_image_path)\n",
    "eeg_image_tensor = transform(eeg_image).unsqueeze(0).to(device)\n",
    "\n",
    "ecog_image_path = data_item[\"ecog_image\"]\n",
    "ecog_image = to_pil(ecog_image_path)\n",
    "ecog_image_tensor = transform(ecog_image).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "# Модель forward принимает тензор времени t, тензор входа (например, eeg_image) и условие (ecog_image)\n",
    "with torch.no_grad():\n",
    "    if USE_TORCH_DIFFEQ:\n",
    "        # Пример траектории для преобразования ЭЭГ в ЭКоГ\n",
    "        traj = torchdiffeq.odeint(\n",
    "            lambda t, x: model_SB.forward(t, x),\n",
    "            eeg_image_tensor,\n",
    "            torch.linspace(0, 1, 2, device=device),\n",
    "            atol=1e-4,\n",
    "            rtol=1e-4,\n",
    "            method=\"dopri5\",\n",
    "        )\n",
    "    else:\n",
    "        traj = node.trajectory(\n",
    "            eeg_image_tensor,  # Входные данные ЭЭГ\n",
    "            t_span=torch.linspace(0, 1, 2, device=device),  # Временной интервал\n",
    "        )\n",
    "\n",
    "eeg_image_display = ToPILImage()(eeg_image_tensor.squeeze(0).cpu())\n",
    "ecog_image_display = ToPILImage()(ecog_image_tensor.squeeze(0).cpu())\n",
    "\n",
    "generated_ecog = traj[-1, :1].view([-1, 4, 128, 128]).clip(-1, 1)\n",
    "grid = make_grid(generated_ecog, value_range=(-1, 1), padding=0, nrow=1)\n",
    "generated_ecog_display = ToPILImage()(grid)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].imshow(eeg_image_display)\n",
    "axs[0].set_title(\"Input EEG\")\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(ecog_image_display)\n",
    "axs[1].set_title(\"Target ECoG\")\n",
    "axs[1].axis('off')\n",
    "axs[2].imshow(generated_ecog_display)\n",
    "axs[2].set_title(\"Generated ECoG from EEG\")\n",
    "axs[2].axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
